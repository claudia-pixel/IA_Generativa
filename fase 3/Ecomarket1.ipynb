{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "La empresa EcoMarket, dedicada a la venta de productos sostenibles, se encuentra en pleno crecimiento. Su departamento de soporte ha identificado un cuello de botella, debido a que recibe miles de consultas diarias a través de chat, correo electrónico y redes sociales.\n",
        "\n",
        "Este notebook está diseñado para resolver el 80% de las consultas repetitivas, tales como el estado de los pedidos, devoluciones y características de los productos. Para ello, se utilizó el modelo Gemini Flash Latest, complementado con RAG (Retrieval-Augmented Generation) para garantizar respuestas más precisas y fundamentadas."
      ],
      "metadata": {
        "id": "VV9qOMTDPJUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 0. Configuración inicial\n",
        "# ==============================\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata # Importar userdata para acceder a secretos\n",
        "\n",
        "# Obtener la clave de API de Google desde los secretos de Colab\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise ValueError(\"GOOGLE_API_KEY not found in Colab secrets.\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\" Clave de API de Google establecida y configuración de Gemini completada.\")\n",
        "\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\" Secreto 'GOOGLE_API_KEY' no encontrado. Por favor, añádelo en Colab Secrets.\")\n",
        "    GOOGLE_API_KEY = None\n",
        "except ValueError as e:\n",
        "    print(f\" Error al obtener la clave de API de Google: {e}\")\n",
        "    GOOGLE_API_KEY = None\n",
        "except Exception as e:\n",
        "    print(f\" Error al configurar la API de Gemini: {e}\")\n",
        "    GOOGLE_API_KEY = None # Asegura que GOOGLE_API_KEY sea None si falla la configuración inicial\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 1. Importar librerías\n",
        "# ==============================\n",
        "import re\n",
        "from typing import Dict, Optional, List\n",
        "# from transformers import pipeline # Ya no es necesario para Gemini\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "# import torch # Ya no es necesario directamente para Gemini\n",
        "\n",
        "# ==============================\n",
        "# 2. Definir clase EcoMarket RAG\n",
        "# ==============================\n",
        "class EcoMarketAsistenteRAGEmbeddings:\n",
        "    def __init__(self): # No necesitamos 'device' como parámetro si usamos Gemini\n",
        "        # Base de datos simulada\n",
        "        self.pedidos_db = {\n",
        "            \"12345\": {\"nombre\": \"María García\", \"estado\": \"en tránsito\", \"carrier\": \"DHL Express\", \"fecha\": \"2025-09-26\"},\n",
        "            \"12346\": {\"nombre\": \"Juan Pérez\", \"estado\": \"procesando\", \"carrier\": \"Servientrega\", \"fecha\": \"2025-09-28\"},\n",
        "            \"12347\": {\"nombre\": \"Ana López\", \"estado\": \"entregado\", \"carrier\": \"Coordinadora\", \"fecha\": \"2025-09-24\"},\n",
        "        }\n",
        "\n",
        "        # Documentos adicionales (para RAG: políticas, FAQs, etc.)\n",
        "        self.documentos = [\n",
        "            \"Las devoluciones se aceptan hasta 30 días después de la compra.\",\n",
        "            \"Los pedidos se entregan generalmente en un plazo de 3 a 5 días hábiles.\",\n",
        "            \"Los clientes pueden solicitar un reembolso completo, crédito en tienda o reemplazo.\",\n",
        "            \"El pedido en tránsito significa que está en camino con la transportadora.\",\n",
        "            \"EcoMarket trabaja con DHL Express, Servientrega y Coordinadora como carriers principales.\"\n",
        "        ]\n",
        "\n",
        "        # -------------------- Embeddings --------------------\n",
        "        self.embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        self.doc_embeddings = self.embedder.encode(self.documentos, convert_to_tensor=False)\n",
        "\n",
        "        # Guardar último pedido mencionado\n",
        "        self.pedido_actual = None\n",
        "\n",
        "        # -------------------- Modelo Gemini Flash --------------------\n",
        "        model_name = \"gemini-flash-latest\"\n",
        "        try:\n",
        "            # Verificar si la clave de API fue configurada correctamente\n",
        "            if GOOGLE_API_KEY:\n",
        "                 self.generator = genai.GenerativeModel(model_name)\n",
        "                 print(f\"Modelo Gemini '{model_name}' cargado correctamente.\")\n",
        "            else:\n",
        "                 self.generator = None\n",
        "                 print(\" No se pudo cargar el modelo Gemini. Asegúrate de que tu clave de API de Google esté configurada en Colab Secrets.\")\n",
        "        except Exception as e:\n",
        "            print(f\" Error al cargar el modelo Gemini '{model_name}': {e}\")\n",
        "            self.generator = None\n",
        "\n",
        "\n",
        "        # Plantilla base optimizada\n",
        "        # Adaptado para el formato de prompt de Gemini\n",
        "        self.prompt_base = \"\"\"Eres un asistente de atención al cliente de EcoMarket.\n",
        "Responde en español, de forma empática, clara y concisa.\n",
        "Usa solo los datos proporcionados, sin inventar información.\n",
        "\n",
        "Pedido {id_pedido}:\n",
        "- Cliente: {nombre}\n",
        "- Estado: {estado}\n",
        "- Carrier: {carrier}\n",
        "- Fecha estimada: {fecha}\n",
        "\n",
        "Información adicional relevante:\n",
        "{contexto}\n",
        "\n",
        "Pregunta del cliente: {mensaje_cliente}\n",
        "\n",
        "Respuesta concisa:\"\"\"\n",
        "\n",
        "    # -------------------- Funciones auxiliares --------------------\n",
        "    def extraer_numero_pedido(self, mensaje: str) -> Optional[str]:\n",
        "        patrones = [r'#(\\d+)', r'pedido\\s*(\\d+)', r'orden\\s*(\\d+)']\n",
        "        for patron in patrones:\n",
        "            match = re.search(patron, mensaje.lower())\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "        return None\n",
        "\n",
        "    def obtener_datos_pedido(self, id_pedido: str) -> Optional[Dict]:\n",
        "        return self.pedidos_db.get(id_pedido)\n",
        "\n",
        "    def recuperar_contexto(self, consulta: str, top_k: int = 2) -> List[str]:\n",
        "        \"\"\"Busca documentos relevantes usando embeddings semánticos\"\"\"\n",
        "        consulta_emb = self.embedder.encode([consulta], convert_to_tensor=False)[0]\n",
        "        similitudes = np.dot(self.doc_embeddings, consulta_emb) / (\n",
        "            np.linalg.norm(self.doc_embeddings, axis=1) * np.linalg.norm(consulta_emb)\n",
        "        )\n",
        "        indices = np.argsort(similitudes)[-top_k:][::-1]\n",
        "        return [self.documentos[i] for i in indices]\n",
        "\n",
        "    # -------------------- Generar respuesta --------------------\n",
        "    def generar_respuesta(self, mensaje_cliente: str) -> str:\n",
        "        # Verificar si el pipeline se inicializó correctamente\n",
        "        if not self.generator:\n",
        "            return \"El asistente no está disponible. Asegúrate de que tu clave de API de Google sea válida y se pudo cargar el modelo Gemini.\"\n",
        "\n",
        "        id_pedido = self.extraer_numero_pedido(mensaje_cliente)\n",
        "\n",
        "        if id_pedido:\n",
        "            self.pedido_actual = id_pedido\n",
        "        elif not self.pedido_actual:\n",
        "            return \"Hola, para ayudarte necesito el número de pedido. Por favor proporciónalo.\"\n",
        "        else:\n",
        "            id_pedido = self.pedido_actual\n",
        "\n",
        "        datos = self.obtener_datos_pedido(id_pedido)\n",
        "        if not datos:\n",
        "            return f\"No encontré información del pedido #{id_pedido}. Verifica el número.\"\n",
        "\n",
        "        # Recuperar contexto adicional (RAG con embeddings)\n",
        "        contexto = \"\\n\".join(self.recuperar_contexto(mensaje_cliente))\n",
        "\n",
        "        # Construir prompt\n",
        "        prompt = self.prompt_base.format(\n",
        "            nombre=datos[\"nombre\"],\n",
        "            id_pedido=id_pedido,\n",
        "            estado=datos[\"estado\"],\n",
        "            carrier=datos[\"carrier\"],\n",
        "            fecha=datos[\"fecha\"],\n",
        "            contexto=contexto,\n",
        "            mensaje_cliente=mensaje_cliente\n",
        "        )\n",
        "\n",
        "        # Generar con Gemini\n",
        "        try:\n",
        "            response = self.generator.generate_content(prompt)\n",
        "            # Acceder al texto generado. Depende del formato de la respuesta de Gemini.\n",
        "            # Algunas respuestas pueden necesitar un manejo de seguridad (safety ratings).\n",
        "            if response and response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
        "                 respuesta = response.candidates[0].content.parts[0].text\n",
        "            else:\n",
        "                 return \" El modelo Gemini no pudo generar una respuesta válida para esta consulta.\"\n",
        "        except Exception as e:\n",
        "            return f\" Error al generar respuesta con Gemini: {e}\"\n",
        "\n",
        "\n",
        "        # No es necesario postprocesado de re.split si Gemini responde limpio según el prompt\n",
        "        return respuesta\n",
        "\n",
        "# ==============================\n",
        "# 3. Prueba rápida\n",
        "# ==============================\n",
        "if __name__ == \"__main__\":\n",
        "    # Verificar si la clave de API de Google fue configurada\n",
        "    if GOOGLE_API_KEY:\n",
        "        asistente = EcoMarketAsistenteRAGEmbeddings()\n",
        "        # Verificar si el modelo Gemini se inicializó correctamente dentro de la clase\n",
        "        if asistente.generator:\n",
        "            casos = [\n",
        "                \"¿Dónde está mi pedido #12345?\",\n",
        "                \"Quiero saber cómo funcionan las devoluciones\",\n",
        "                \"Mi pedido 12346 no ha llegado aún\",\n",
        "                \"¿Qué transportadoras trabajan con ustedes?\"\n",
        "            ]\n",
        "\n",
        "            for caso in casos:\n",
        "                print(f\"Cliente: {caso}\")\n",
        "                print(f\"Asistente: {asistente.generar_respuesta(caso)}\\n\")\n",
        "        else:\n",
        "            print(\" No se pudo inicializar el asistente debido a un error previo en la carga del modelo.\")\n",
        "    else:\n",
        "        print(\" No se pudo ejecutar la prueba rápida porque la clave de API de Google no es válida o no se encontró.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "nbPGTfjTL4QE",
        "outputId": "8d604450-cf1f-4ebe-808d-d325ce62af6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Clave de API de Google establecida y configuración de Gemini completada.\n",
            "Modelo Gemini 'gemini-flash-latest' cargado correctamente.\n",
            "Cliente: ¿Dónde está mi pedido #12345?\n",
            "Asistente: Hola María. Entiendo su consulta.\n",
            "\n",
            "Su pedido #12345 está actualmente **en tránsito** con DHL Express, lo que significa que ya está en camino. La fecha estimada de entrega es el **26 de septiembre de 2025**.\n",
            "\n",
            "Recuerde que el plazo de entrega habitual para pedidos en tránsito es de 3 a 5 días hábiles.\n",
            "\n",
            "Cliente: Quiero saber cómo funcionan las devoluciones\n",
            "Asistente: Hola María,\n",
            "\n",
            "Entiendo su consulta sobre las devoluciones.\n",
            "\n",
            "Le confirmo que aceptamos devoluciones hasta 30 días después de la compra.\n",
            "\n",
            "Cliente: Mi pedido 12346 no ha llegado aún\n",
            "Asistente: Hola Juan Pérez, entiendo su preocupación.\n",
            "\n",
            "Su pedido 12346 se encuentra actualmente en estado **\"procesando\"**. Será entregado por Servientrega y la fecha estimada de entrega es el **28 de septiembre de 2025**.\n",
            "\n",
            "Cliente: ¿Qué transportadoras trabajan con ustedes?\n",
            "Asistente: ¡Hola, Juan! Para los envíos, trabajamos principalmente con DHL Express, Servientrega y Coordinadora.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo a las respuestas que se obtuvieron al ejecutar el código, podemos sacar las siguientes conclusiones:\n",
        "\n",
        "**Carga y configuración exitosa**: La configuración inicial para acceder a la API de Google y la carga del modelo Gemini Flash Latest (gemini-flash-latest) se realizaron correctamente.\n",
        "\n",
        "**Extracción de número de pedid**o: El asistente fue capaz de identificar el número de pedido (#12345 y 12346) en las preguntas del cliente utilizando las expresiones regulares definidas.\n",
        "\n",
        "**Recuperación de datos de pedido**: Se pudo obtener la información correcta (nombre, estado, carrier, fecha) de la base de datos simulada (self.pedidos_db) para los pedidos proporcionados.\n",
        "\n",
        "**Aplicación de RAG**: El mecanismo RAG basado en embeddings funcionó para recuperar información relevante de los documentos adicionales (self.documentos) en función de la consulta del cliente (por ejemplo, al preguntar por devoluciones o transportadoras). Este contexto adicional fue incluido en el prompt para el modelo.\n",
        "\n",
        "**Generación de respuestas coherente**s: El modelo Gemini, utilizando el prompt que incluía los datos del pedido y el contexto recuperado, generó respuestas que son relevantes, concisas y están en español, como se solicitó en el prompt base. Las respuestas reflejan la información proporcionada (estado del pedido, políticas de devolución, transportadoras).\n",
        "\n",
        "**Manejo de consultas sin número de pedido** (después de una inicial): El asistente recuerda el último número de pedido mencionado, lo cual es útil para conversaciones de seguimiento.\n",
        "\n",
        "**Manejo de pedidos no encontrados**: El asistente identificó correctamente cuando un número de pedido no estaba en la base de datos simulada.\n",
        "\n",
        "En resumen, el notebook demuestra que se logró implementar un asistente básico de atención al cliente utilizando el modelo Gemini con una capa de RAG para proporcionar respuestas informadas basadas en datos estructurados (pedidos) y no estructurados (documentos/FAQs)."
      ],
      "metadata": {
        "id": "SXKKxj2qRRrv"
      }
    }
  ]
}