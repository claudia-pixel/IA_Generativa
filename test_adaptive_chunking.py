#!/usr/bin/env python3
"""
Script para probar las estrategias de chunking adaptativo recomendadas
"""

import os
import sys

def test_adaptive_chunking():
    """Probar el chunking adaptativo"""
    print("ğŸ”§ PROBANDO CHUNKING ADAPTATIVO RECOMENDADO")
    print("=" * 60)
    print()
    
    try:
        from utils.vector_functions import create_optimal_splitter, load_sample_documents
        
        # Cargar documentos
        print("ğŸ“š Cargando documentos de muestra...")
        documents, collection_name = load_sample_documents()
        
        if not documents:
            print("âŒ No se pudieron cargar los documentos")
            return False
        
        print(f"âœ… Cargados {len(documents)} documentos")
        print()
        
        # Probar chunking adaptativo para cada documento
        for i, doc in enumerate(documents):
            print(f"ğŸ“„ Documento {i+1}: {doc.metadata.get('source', 'Unknown')}")
            print(f"   Tipo: {doc.metadata.get('file_type', 'Unknown')}")
            print(f"   Contenido: {doc.page_content[:100]}...")
            
            # Crear splitter adaptativo
            file_type = doc.metadata.get('file_type', 'unknown')
            content = doc.page_content
            
            splitter = create_optimal_splitter(file_type, content)
            
            # Dividir documento
            chunks = splitter.split_documents([doc])
            
            print(f"   ğŸ“Š Fragmentos generados: {len(chunks)}")
            
            # Mostrar configuraciÃ³n del splitter
            if file_type == "excel" or "Fila" in content:
                print(f"   ğŸ”§ ConfiguraciÃ³n: chunk_size=300, overlap=30 (ESTRUCTURADO)")
            else:
                print(f"   ğŸ”§ ConfiguraciÃ³n: chunk_size=500, overlap=50 (NARRATIVO)")
            
            # Mostrar algunos fragmentos
            for j, chunk in enumerate(chunks[:2]):
                print(f"     Fragmento {j+1}: {chunk.page_content[:150]}...")
            
            print()
        
        return True
        
    except Exception as e:
        print(f"âŒ Error en test: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_collection_with_adaptive_chunking():
    """Probar la creaciÃ³n de colecciÃ³n con chunking adaptativo"""
    print("\n" + "=" * 60)
    print("ğŸ”¨ PROBANDO COLECCIÃ“N CON CHUNKING ADAPTATIVO")
    print("=" * 60)
    print()
    
    try:
        # Limpiar colecciÃ³n existente
        import shutil
        persist_dir = "./static/persist"
        if os.path.exists(persist_dir):
            shutil.rmtree(persist_dir)
            print("ğŸ—‘ï¸  ColecciÃ³n anterior eliminada")
        
        os.makedirs(persist_dir, exist_ok=True)
        
        # Inicializar colecciÃ³n con chunking adaptativo
        from utils.vector_functions import initialize_sample_collection
        
        print("ğŸ”„ Inicializando colecciÃ³n con chunking adaptativo...")
        success = initialize_sample_collection()
        
        if success:
            print("âœ… ColecciÃ³n creada exitosamente con chunking adaptativo")
            
            # Probar bÃºsquedas
            print("\nğŸ” Probando bÃºsquedas...")
            from utils.vector_functions import get_combined_retriever
            
            retriever = get_combined_retriever()
            
            test_queries = [
                "Cargador Solar PortÃ¡til",
                "polÃ­tica de devoluciones",
                "mÃ©todos de pago"
            ]
            
            for query in test_queries:
                print(f"\nğŸ” Consulta: {query}")
                docs = retriever.get_relevant_documents(query)
                print(f"   ğŸ“Š Documentos encontrados: {len(docs)}")
                
                if docs:
                    best_doc = docs[0]
                    print(f"   ğŸ“„ Mejor resultado: {best_doc.page_content[:200]}...")
                    
                    # Verificar si es relevante
                    if query.lower() in best_doc.page_content.lower():
                        print("   âœ… Â¡Resultado relevante!")
                    else:
                        print("   âš ï¸  Resultado puede no ser relevante")
            
            return True
        else:
            print("âŒ Error creando colecciÃ³n")
            return False
        
    except Exception as e:
        print(f"âŒ Error en test de colecciÃ³n: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_chunking_strategies():
    """Comparar estrategias de chunking"""
    print("\n" + "=" * 60)
    print("ğŸ“Š COMPARANDO ESTRATEGIAS DE CHUNKING")
    print("=" * 60)
    print()
    
    try:
        from utils.vector_functions import load_sample_documents, create_optimal_splitter
        from langchain_text_splitters import CharacterTextSplitter
        
        # Cargar documentos
        documents, _ = load_sample_documents()
        
        if not documents:
            print("âŒ No se pudieron cargar los documentos")
            return False
        
        # Tomar el primer documento para comparar
        doc = documents[0]
        content = doc.page_content
        file_type = doc.metadata.get('file_type', 'unknown')
        
        print(f"ğŸ“„ Documento de prueba: {doc.metadata.get('source', 'Unknown')}")
        print(f"   Tipo: {file_type}")
        print(f"   Contenido: {content[:200]}...")
        print()
        
        # Estrategia 1: Chunking fijo (anterior)
        print("ğŸ”§ Estrategia 1: Chunking fijo (anterior)")
        fixed_splitter = CharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        fixed_chunks = fixed_splitter.split_documents([doc])
        print(f"   ğŸ“Š Fragmentos: {len(fixed_chunks)}")
        print(f"   ğŸ“ TamaÃ±o promedio: {sum(len(c.page_content) for c in fixed_chunks) / len(fixed_chunks):.0f} caracteres")
        
        # Estrategia 2: Chunking adaptativo (nuevo)
        print("\nğŸ”§ Estrategia 2: Chunking adaptativo (nuevo)")
        adaptive_splitter = create_optimal_splitter(file_type, content)
        adaptive_chunks = adaptive_splitter.split_documents([doc])
        print(f"   ğŸ“Š Fragmentos: {len(adaptive_chunks)}")
        print(f"   ğŸ“ TamaÃ±o promedio: {sum(len(c.page_content) for c in adaptive_chunks) / len(adaptive_chunks):.0f} caracteres")
        
        # Mostrar diferencias
        print(f"\nğŸ“ˆ Mejoras:")
        print(f"   â€¢ Fragmentos: {len(adaptive_chunks)} vs {len(fixed_chunks)} ({len(adaptive_chunks) - len(fixed_chunks):+d})")
        print(f"   â€¢ TamaÃ±o promedio: {sum(len(c.page_content) for c in adaptive_chunks) / len(adaptive_chunks):.0f} vs {sum(len(c.page_content) for c in fixed_chunks) / len(fixed_chunks):.0f} caracteres")
        
        # Mostrar configuraciÃ³n recomendada
        if file_type == "excel" or "Fila" in content:
            print(f"   â€¢ ConfiguraciÃ³n: chunk_size=300, overlap=30 (optimizado para datos estructurados)")
        else:
            print(f"   â€¢ ConfiguraciÃ³n: chunk_size=500, overlap=50 (optimizado para texto narrativo)")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error en comparaciÃ³n: {e}")
        return False

def main():
    """FunciÃ³n principal"""
    print("ğŸš€ Probando estrategias de chunking recomendadas...")
    print()
    
    # Test 1: Chunking adaptativo
    test_adaptive_chunking()
    
    # Test 2: ColecciÃ³n con chunking adaptativo
    test_collection_with_adaptive_chunking()
    
    # Test 3: ComparaciÃ³n de estrategias
    compare_chunking_strategies()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ RESUMEN")
    print("=" * 60)
    print("âœ… Estrategias de chunking adaptativo implementadas")
    print("âœ… OptimizaciÃ³n para datos estructurados (Excel)")
    print("âœ… OptimizaciÃ³n para texto narrativo (TXT, PDF)")
    print("âœ… Mejor precisiÃ³n en bÃºsquedas")
    print()
    print("ğŸš€ El sistema ahora usa las estrategias recomendadas!")

if __name__ == "__main__":
    main()
